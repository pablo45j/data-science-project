{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/dl-facilito-g2/blob/main/notebooks/Deep_Learning_Clase_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Drowsiness Detection\n",
        "\n",
        "> **Descripción:** Este proyecto consiste en el entrenamiento de una red neuronal para determinar la somnolencia de conductos a través de la detección de los ojos cerrados.<br>\n",
        "> **Autor:** [Pablo Juárez del Valle] <br>\n",
        "> **Contacto:** [Gmail](pablo.juarezdelvalle@gmail.com) \n",
        "\n",
        "\n",
        "## Contenido\n",
        "\n",
        "### Preámbulo\n",
        "\n",
        "- Reconocimiento de imagenes\n",
        "\n",
        "### Definición del problema\n",
        "\n",
        "La Organización Mundial de la Salud (OMS) estima que anualmente 1,35 millones de personas en el mundo resultan víctimas mortales por lesiones del tránsito y entre 20 y 50 millones padecen secuelas físicas y psicológicas, siendo esta una de las principales causas de discapacidad [1]. En Argentina, considerando el año 2019 por ser el último anterior a la aparición de la pandemia a causa del COVID-19 (hecho que modificó los datos de movilidad a nivel nacional), la Agencia Nacional de Seguridad Vial (ANSV) registró 99.221 siniestros viales con víctimas [2], los cuales dejaron como consecuencia 4.911 personas fallecidas a causa de la inseguridad vial en Argentina.\n",
        "\n",
        "El estrés es la reacción del cuerpo a un desafío o demanda que puede provenir de cualquier situación o pensamiento de furia, ansiedad, nervios o frustración. En cambio, la fatiga, si bien coloquialmente es sinónimo de cansancio y ambas palabras se utilizan indistintamente, se encuentra acompañada de otros síntomas generales como dolor generalizado, ansiedad, depresión, apatía, alteraciones del sueño, o alteraciones de la memoria o de la concentración; mientras que el cansancio se origina como consecuencia de una actividad física [3].\n",
        "\n",
        "El estrés y la fatiga son factores de riesgo que, en general, son difíciles de medir y ser admitidos por las/os parecientes; mucho más cuando se presentan en rubros laborales donde la conducción de vehículos es la tarea principal y la prolongación del horario tras el volante reditúa económicamente. Conducir es una tarea compleja que involucra aspectos como la percepción, el tiempo de respuesta y la capacidad física, haciendo de la coordinación moto-sensorial un punto fundamental para realizar maniobras que requieren de varios movimientos simultáneos y de manera coordinada. En tal sentido, y en línea con la literatura especializada, se entiende a la conducción de vehículos bajo fatiga y/o estrés como uno de los principales factores de riesgo de la siniestralidad vial [4].\n",
        "\n",
        "### Objetivos\n",
        "\n",
        "El objetivo del proyecto consiste en diseñar una ANN convolucional y entrenarla para la detección de somnolencia mediante la obtención de fotos. Los datos de entrenamiento son obtenidos de Kaggle. [5]\n",
        "1. Se implementará una red convolucional siguiendo el modelo LeNet5 de Yann LeCun para su entrenamiento y posterior predicción.\n",
        "2. Se desarrollará una API para cargar fotos de ojos y detectar la somnolencia.\n",
        "3. Sentar las bases del prototipo para implementarlo en un dispositivo que pueda instalarse en un vehiculo y mediante la toma de fotos pueda detectar si el conductor tiene sueño.\n",
        "\n",
        "#### Referencias\n",
        "\n",
        "1. <a href=\"www.who.int/publications/i/item/9789241565684\">OMS (2018): Global Status Report on Road Safety.</a>\n",
        "2. <a href=\"www.argentina.gob.ar/sites/default/files/2018/12/ansv_ov_anuario_estadistico_2019_final.pdf\">Anuario nuario Estadístico de la Seguridad Vial 2019 de la ANSV.</a>\n",
        "3. <a href=\"https://www.infosalus.com/salud-investigacion/noticia-fatiga-cuando-debemos-sospechar-algo-no-va-bien-20210720083435.html\">Publicación del 20-7-2021 en el sitio Infosalus.com, editado por Europapress, España.</a>\n",
        "4. <a href=\"www.argentina.gob.ar/sites/default/files/ansv_observatorio_situacion_seguridad_vial_arg.pdf\">ANSV (2018): Situación de la seguridad vial en Argentina.</a> \n",
        "5. <a href=\"https://www.kaggle.com/datasets/prasadvpatil/mrl-dataset\">Detección de somnolencia en conductores</a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Preámbulo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOOWWpUv32iz"
      },
      "source": [
        "### Redes Convolucionales\n",
        "\n",
        "\n",
        "Una red neuronal convolucional es un tipo de red neuronal artificial donde las neuronas artificiales, corresponden a campos receptivos de una manera muy similar a las neuronas en la corteza visual primaria de un cerebro biológico, es decir distintas capas. Donde cada capa en la que el modelo convoluciona, aplica un filtro por ejemplo, aportando información.\n",
        "Este tipo de redes son muy efectivas para tareas de visión artificial, como en la clasificación y segmentación de imágenes, entre otras aplicaciones.​ \n",
        "\n",
        "Un modelo de red neuronal convolucional profunda, muy difundido por el investigador Yann LeCun, es el modelo LeNet5.\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg\" width=\"60%\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Importación de librerias\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "#Importación de librerias\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tqdm' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m Y \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mdir\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/home/pablo/Documents/workspace/DS/https:/github.com/pablo45j/data-science-project/data/external/train\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(glob(\u001b[39mdir\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/Open_Eyes/*\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[1;32m      7\u001b[0m     temp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mopen(i)\u001b[39m.\u001b[39mresize((\u001b[39m64\u001b[39m,\u001b[39m64\u001b[39m)))\n\u001b[1;32m      8\u001b[0m     X\u001b[39m.\u001b[39mappend(temp)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ],
      "source": [
        "#CARGA DE IMAGENES\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dir=\"drive/MyDrive/train\"\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i in tqdm(glob(dir + '/Open_Eyes/*')):\n",
        "    temp = np.array(Image.open(i).resize((64,64)))\n",
        "    X.append(temp)\n",
        "    Y.append(1)\n",
        "    \n",
        "for i in tqdm(glob(dir + '/Closed_Eyes/*')):\n",
        "    temp = np.array(Image.open(i).resize((64,64)))\n",
        "    X.append(temp)\n",
        "    Y.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kb3YuuW51-b"
      },
      "outputs": [],
      "source": [
        "#NORMALIZANDO LAS IMAGENES\n",
        "\n",
        "# SIN ALGORITMO\n",
        "# X = np.array(X)\n",
        "# X = X/255.0\n",
        "# Y = np.array(Y)\n",
        "\n",
        "# MIN-MAX SCALING ALGORITHM\n",
        "X = (np.array(X) - np.min(X)) / (np.max(X) - np.min(X))\n",
        "X = X/255.0\n",
        "Y = (np.array(Y) - np.min(Y)) / (np.max(Y) - np.min(Y))\n",
        "\n",
        "# zERO STORE ALGORITHM\n",
        "# 'X = (np.array(X) - np.mean(X)) / np.std(X)\n",
        "# X = X/255.0\n",
        "# Y = (np.array(Y) - np.mean(Y)) / np.std(Y)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#EXPANDIENDO LAS DIMENSIONES DEL VECTOR\n",
        "X = np.expand_dims(X,-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DIVIDIENDO LOS DATOS EN DATOS DE ENTRANAMIENTO Y PRUEBA\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#MODELO DE LA RED NEURONAL\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, BatchNormalization, MaxPooling2D,Dropout, Flatten\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "      Input(shape=(64, 64, 1)),\n",
        "\n",
        "      Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu'),\n",
        "      Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', use_bias=False),\n",
        "      BatchNormalization(),\n",
        "      MaxPooling2D(strides = 2),\n",
        "      Dropout(0.3),\n",
        "\n",
        "      Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu'),\n",
        "      Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', use_bias=False),\n",
        "      BatchNormalization(),\n",
        "      MaxPooling2D(strides = 2),\n",
        "      Dropout(0.3),\n",
        "\n",
        "      Flatten(),\n",
        "      Dense(units  = 256, activation = 'relu', use_bias=False),\n",
        "      BatchNormalization(),\n",
        "\n",
        "      Dense(units = 128, use_bias=False, activation = 'relu'),\n",
        "\n",
        "      Dense(units = 84, use_bias=False, activation = 'relu'),\n",
        "      BatchNormalization(),\n",
        "      Dropout(0.3),\n",
        "\n",
        "      Dense(units = 1, activation = 'sigmoid')\n",
        "  ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RbMybth8xL5"
      },
      "source": [
        "COMPILANDO EL MODELO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ENTRENANDO EL MODELO\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath= dir + 'bestModel.h5',\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    verbose =1)\n",
        "model.fit(x_train, y_train, validation_split=0.2, epochs=30, batch_size=32, callbacks=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#EVALUANDO EL MODELO\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#PERFORMANCE DEL MODELO\n",
        "from keras.models import load_model\n",
        "best_model = load_model(dir + '/bestModel.h5')\n",
        "best_model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Predecir Fotos Reales\n",
        "for i in tqdm(glob(dir + '/Pruebas/*')):\n",
        "    temp = np.array(Image.open(i).resize((64,64)))\n",
        "    #temp = (np.array(temp) - np.min(temp)) / (np.max(temp) - np.min(temp))\n",
        "    temp = temp/255.0\n",
        "    plt.imshow(temp)\n",
        "    plt.show()\n",
        "    print(temp)\n",
        "    plt.imshow(x_test[322])\n",
        "    plt.show()\n",
        "    print(x_test[322])\n",
        "    #result = best_model.predict(temp)\n",
        "    #print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CAMBIANDO LAS DIMENSIONES Y REEPLOTEANDO LAS IMAGENES\n",
        "for i in x_test[0:5]:\n",
        "    result = best_model.predict(np.expand_dims(i,0))\n",
        "    plt.imshow(i)\n",
        "    plt.show()\n",
        "    \n",
        "    if result > 0.5:\n",
        "        print('Open')\n",
        "    else:\n",
        "        print(\"Closed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#PREDICCION Y MATRIZ CONFUSION\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "preds = best_model.predict(x_test)\n",
        "preds = (preds >= 0.5).astype(np.int32)\n",
        "cm = confusion_matrix(y_test, preds)\n",
        "df_cm = pd.DataFrame(cm, index=['closed', 'Open'], columns=['Closed', 'Open'])\n",
        "plt.subplot(121)\n",
        "plt.title(\"Confusion matrix\\n\")\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.xlabel(\"Actual\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#PRESICION\n",
        "accuracy = best_model.evaluate(x_test, y_test)[1]\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
